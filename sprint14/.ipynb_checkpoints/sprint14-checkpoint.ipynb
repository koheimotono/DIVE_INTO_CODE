{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint ディープラーニングフレームワーク2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprintの目的  \n",
    "フレームワークのコードを読めるようにする  \n",
    "フレームワークを習得し続けられるようになる  \n",
    "理論を知っている範囲をフレームワークで動かす  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】公式Exampleを分担して実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.2201 - acc: 0.93560s - loss: 0.2260 - acc: 0\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.0974 - acc: 0.96990s - loss: 0.0977 - acc: 0\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0678 - acc: 0.9782\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0524 - acc: 0.9831\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0435 - acc: 0.9857\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0761 - acc: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07610306413671351, 0.9776]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】Iris（2値分類）をKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"../Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,451\n",
      "Trainable params: 5,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0906 18:13:59.587628 4573959616 deprecation.py:323] From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.32399600744247437\n",
      "Test accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 100\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation = tf.nn.relu, input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(100, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1, activation = tf.nn.sigmoid))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=0,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred_proba = model.predict(X_train)[:, 0]\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "\n",
    "# 指標値計算\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】Iris（多値分類）をKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"../Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y[y=='Iris-setosa'] = 2\n",
    "y = y.astype(np.int)\n",
    "y = np.eye(3)[y]           # one hot表現に変換\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 5,653\n",
      "Trainable params: 5,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.010126794688403606\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 100\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation = tf.nn.relu, input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(100, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(3, activation = tf.nn.softmax))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=0,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred_proba = model.predict(X_train)\n",
    "\n",
    "# 確率の一番高いインデックスに変換\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# 指標値計算\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】House PricesをKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"../housing_train.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "\n",
    "y = df[\"SalePrice\"]\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "y = y[:, np.newaxis]\n",
    "# yを対数変換\n",
    "X = np.log(X)\n",
    "\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                150       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,351\n",
      "Trainable params: 5,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 6390437158.575342\n",
      "Test mse: 6390437000.0\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 30\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation = tf.nn.relu, input_shape=(2,)))\n",
    "model.add(tf.keras.layers.Dense(100, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate),\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=0,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "# 指標値計算\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test mse:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】MNISTをKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# 平滑化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "# 前処理\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "y_train = np.eye(10)[y_train]\n",
    "y_test = np.eye(10)[y_test]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 443,610\n",
      "Trainable params: 443,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 12s 250us/sample - loss: 0.3853 - acc: 0.9012 - val_loss: 0.3766 - val_acc: 0.9023\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 11s 229us/sample - loss: 0.2708 - acc: 0.9353 - val_loss: 0.2480 - val_acc: 0.9426\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 11s 227us/sample - loss: 0.2471 - acc: 0.9435 - val_loss: 0.2243 - val_acc: 0.9543\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 11s 228us/sample - loss: 0.2309 - acc: 0.9482 - val_loss: 0.4071 - val_acc: 0.9451\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 11s 236us/sample - loss: 0.2282 - acc: 0.9493 - val_loss: 0.2991 - val_acc: 0.9416\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 11s 238us/sample - loss: 0.2290 - acc: 0.9499 - val_loss: 0.2803 - val_acc: 0.9441\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 11s 239us/sample - loss: 0.2224 - acc: 0.9510 - val_loss: 0.2491 - val_acc: 0.9496\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 11s 237us/sample - loss: 0.2290 - acc: 0.9485 - val_loss: 0.3999 - val_acc: 0.9486\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 11s 238us/sample - loss: 0.2416 - acc: 0.9495 - val_loss: 0.3002 - val_acc: 0.9332\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 12s 243us/sample - loss: 0.2314 - acc: 0.9493 - val_loss: 0.3305 - val_acc: 0.9377\n",
      "Test loss: 0.3565544679180253\n",
      "Test accuracy: 0.9344\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(500, activation = tf.nn.relu, input_shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(100, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred_proba = model.predict(X_train)\n",
    "\n",
    "# 確率の一番高いインデックスに変換\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# 指標値計算\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
